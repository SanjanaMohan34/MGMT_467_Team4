{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cc2ea114",
      "metadata": {
        "id": "cc2ea114"
      },
      "source": [
        "\n",
        "# Unit 2 — Team Classification (Flights, BQML)\n",
        "\n",
        "**Goal (team):** Build an *ops-ready* classifier in **BigQuery ML** to predict **`diverted`** on U.S. flights. Minimal handholding by design.\n",
        "\n",
        "**What you deliver (inside this notebook):**\n",
        "- One **LOGISTIC_REG** model (baseline), one **engineered** model using `TRANSFORM`\n",
        "- **Evaluation** via `ML.EVALUATE` and **confusion matrices** (default 0.5 + your custom threshold)\n",
        "- **Threshold choice** + 3–5 sentence ops justification\n",
        "- Embedded **rubric** below (self-check before submission)\n",
        "\n",
        "> Choose *one* dataset table that exists at your institution:  \n",
        "> • `bigquery-public-data.faa.us_flights` **or** `bigquery-public-data.flights.*`  \n",
        "> Make sure the table has `carrier`, `dep_delay`, `arr_delay` (for filters), `origin`, `dest`, `diverted` (or equivalent).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Original Path using provided code in template"
      ],
      "metadata": {
        "id": "1iJwvllE1ACD"
      },
      "id": "1iJwvllE1ACD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c294930",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c294930",
        "outputId": "e47a174e-5496-4ac6-9226-10c721eaec39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BQ Project: mgmt-467-55510\n",
            "Source table: bigquery-public-data.flights.ontime\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import auth\n",
        "from google.cloud import bigquery\n",
        "\n",
        "# Authenticate to Google\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Set up project and dataset details\n",
        "PROJECT_ID = \"mgmt-467-55510\"      # your project\n",
        "REGION     = \"us\"\n",
        "TABLE_PATH = \"bigquery-public-data.flights.ontime\"  # Changed to the correct public FAA flights dataset\n",
        "\n",
        "os.environ[\"PROJECT_ID\"] = PROJECT_ID\n",
        "os.environ[\"REGION\"]     = REGION\n",
        "\n",
        "# Create BigQuery client\n",
        "bq = bigquery.Client(project=PROJECT_ID)\n",
        "\n",
        "print(\"BQ Project:\", PROJECT_ID)\n",
        "print(\"Source table:\", TABLE_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0083eaf9",
      "metadata": {
        "id": "0083eaf9"
      },
      "source": [
        "### Quick sanity check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e402070",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "0e402070",
        "outputId": "6a372fb2-0c9a-405f-e1f2-ca673e5c1caf"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "Forbidden",
          "evalue": "403 Access Denied: Table bigquery-public-data:flights.ontime: User does not have permission to query table bigquery-public-data:flights.ontime, or perhaps it does not exist.; reason: accessDenied, message: Access Denied: Table bigquery-public-data:flights.ontime: User does not have permission to query table bigquery-public-data:flights.ontime, or perhaps it does not exist.\n\nLocation: US\nJob ID: e1c5638d-2a80-4dbd-8864-3ae552bfd536\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mForbidden\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3702694691.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpreview_sql\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"SELECT * FROM `{TABLE_PATH}` LIMIT 5\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreview_sql\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/job/query.py\u001b[0m in \u001b[0;36mto_dataframe\u001b[0;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, max_results, geography_as_object, bool_dtype, int_dtype, float_dtype, string_dtype, date_dtype, datetime_dtype, time_dtype, timestamp_dtype, range_date_dtype, range_datetime_dtype, range_timestamp_dtype)\u001b[0m\n\u001b[1;32m   2157\u001b[0m                 \u001b[0;34m:\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mshapely\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mlibrary\u001b[0m \u001b[0mcannot\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mimported\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2158\u001b[0m         \"\"\"\n\u001b[0;32m-> 2159\u001b[0;31m         \u001b[0mquery_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait_for_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_bar_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2160\u001b[0m         return query_result.to_dataframe(\n\u001b[1;32m   2161\u001b[0m             \u001b[0mbqstorage_client\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbqstorage_client\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/_tqdm_helpers.py\u001b[0m in \u001b[0;36mwait_for_query\u001b[0;34m(query_job, progress_bar_type, max_results)\u001b[0m\n\u001b[1;32m    105\u001b[0m     )\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprogress_bar\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mquery_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/job/query.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, page_size, max_results, retry, timeout, start_index, job_retry)\u001b[0m\n\u001b[1;32m   1771\u001b[0m                 \u001b[0;31m# Since is_job_done() calls jobs.getQueryResults, which is a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m                 \u001b[0;31m# long-running API, don't delay the next request at all.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_job_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             )\n\u001b[0;32m--> 294\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    295\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;31m# defer to shared logic for handling errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             next_sleep = _retry_error_helper(\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0mdeadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_base.py\u001b[0m in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0moriginal_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         )\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfinal_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msource_exc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mon_error_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mon_error_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ASYNC_RETRY_WARNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/job/query.py\u001b[0m in \u001b[0;36mis_job_done\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1720\u001b[0m                         \u001b[0;31m# `job_retry` predicate.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1721\u001b[0m                         \u001b[0mrestart_query_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1722\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mjob_failed_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1723\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1724\u001b[0m                         \u001b[0;31m# Make sure that the _query_results are cached so we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mForbidden\u001b[0m: 403 Access Denied: Table bigquery-public-data:flights.ontime: User does not have permission to query table bigquery-public-data:flights.ontime, or perhaps it does not exist.; reason: accessDenied, message: Access Denied: Table bigquery-public-data:flights.ontime: User does not have permission to query table bigquery-public-data:flights.ontime, or perhaps it does not exist.\n\nLocation: US\nJob ID: e1c5638d-2a80-4dbd-8864-3ae552bfd536\n"
          ]
        }
      ],
      "source": [
        "preview_sql = f\"SELECT * FROM `{TABLE_PATH}` LIMIT 5\"\n",
        "df = bq.query(preview_sql).to_dataframe()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26942614",
      "metadata": {
        "id": "26942614"
      },
      "source": [
        "\n",
        "## 1) Canonical mapping (adjust as needed)\n",
        "Map to a minimal schema used in the rest of the notebook:\n",
        "- `flight_date` (DATE), `dep_delay` (NUM), `distance` (NUM), `carrier` (STRING), `origin` (STRING), `dest` (STRING), `diverted` (BOOL)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfe13f2d",
      "metadata": {
        "id": "cfe13f2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be1fe882-5b8c-4875-c60d-dcfad0bd3b28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "WITH canonical_flights AS (\n",
            "  SELECT\n",
            "    CAST(FlightDate AS DATE) AS flight_date,\n",
            "    CAST(DepDelay AS FLOAT64) AS dep_delay,\n",
            "    CAST(distance  AS FLOAT64) AS distance,\n",
            "    CAST(Reporting_Airline   AS STRING)  AS carrier,\n",
            "    CAST(Origin    AS STRING)  AS origin,\n",
            "    CAST(Dest AS STRING) AS dest,\n",
            "    CAST((CASE WHEN SAFE_CAST(Diverted AS INT64)=1 OR LOWER(CAST(Diverted AS STRING))='true' THEN TRUE ELSE FALSE END) AS BOOL) AS diverted\n",
            "  FROM `bigquery-public-data.flights.ontime`\n",
            "  WHERE DepDelay IS NOT NULL\n",
            ")\n",
            "\n",
            "...\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Adjust ONLY if your table uses different column names.\n",
        "CANONICAL_BASE_SQL = f'''\n",
        "WITH canonical_flights AS (\n",
        "  SELECT\n",
        "    CAST(FlightDate AS DATE) AS flight_date,\n",
        "    CAST(DepDelay AS FLOAT64) AS dep_delay,\n",
        "    CAST(distance  AS FLOAT64) AS distance,\n",
        "    CAST(Reporting_Airline   AS STRING)  AS carrier,\n",
        "    CAST(Origin    AS STRING)  AS origin,\n",
        "    CAST(Dest AS STRING) AS dest,\n",
        "    CAST((CASE WHEN SAFE_CAST(Diverted AS INT64)=1 OR LOWER(CAST(Diverted AS STRING))='true' THEN TRUE ELSE FALSE END) AS BOOL) AS diverted\n",
        "  FROM `{TABLE_PATH}`\n",
        "  WHERE DepDelay IS NOT NULL\n",
        ")\n",
        "'''\n",
        "print(CANONICAL_BASE_SQL[:600] + \"\\n...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3310fef4",
      "metadata": {
        "id": "3310fef4"
      },
      "source": [
        "### 2) Split (80/20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e0b30dd",
      "metadata": {
        "id": "9e0b30dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00c16522-a02a-4ba5-9deb-547050cdf37a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ", split AS (\n",
            "  SELECT cf.*,\n",
            "         CASE WHEN RAND() < 0.8 THEN 'TRAIN' ELSE 'EVAL' END AS split\n",
            "  FROM canonical_flights cf\n",
            ")\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "SPLIT_CLAUSE = r'''\n",
        ", split AS (\n",
        "  SELECT cf.*,\n",
        "         CASE WHEN RAND() < 0.8 THEN 'TRAIN' ELSE 'EVAL' END AS split\n",
        "  FROM canonical_flights cf\n",
        ")\n",
        "'''\n",
        "print(SPLIT_CLAUSE)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25c00049",
      "metadata": {
        "id": "25c00049"
      },
      "source": [
        "\n",
        "## 3) Baseline model — LOGISTIC_REG (`diverted`)\n",
        "Use **only** a small set of signals for the baseline (keep it honest).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0389aec2",
      "metadata": {
        "id": "0389aec2"
      },
      "source": [
        "### Confusion matrix — default 0.5 threshold"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "249abf6f",
      "metadata": {
        "id": "249abf6f"
      },
      "source": [
        "### Confusion matrix — your custom threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7e85624",
      "metadata": {
        "id": "f7e85624",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "c3105108-5cb1-404f-d45b-acb2b81e988d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'MODEL_BASE' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4037773300.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mSELECT\u001b[0m \u001b[0mcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicted_diverted_probs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOFFSET\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprob\u001b[0m \u001b[0mAS\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mFROM\u001b[0m \u001b[0msplit\u001b[0m \u001b[0mcf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     JOIN ML.PREDICT(MODEL `{MODEL_BASE}`,\n\u001b[0m\u001b[1;32m     15\u001b[0m           (SELECT dep_delay, distance, carrier, origin, dest, EXTRACT(DAYOFWEEK FROM flight_date) AS day_of_week\n\u001b[1;32m     16\u001b[0m            FROM split)) AS p\n",
            "\u001b[0;31mNameError\u001b[0m: name 'MODEL_BASE' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "CUSTOM_THRESHOLD = 0.75  # TODO: justify in ops terms\n",
        "\n",
        "cm_thresh_sql = f'''\n",
        "{CANONICAL_BASE_SQL}\n",
        "{SPLIT_CLAUSE}\n",
        "\n",
        "WITH scored AS (\n",
        "  SELECT\n",
        "    cf.diverted AS label,\n",
        "    CAST(score >= {CUSTOM_THRESHOLD} AS BOOL) AS pred_label\n",
        "  FROM (\n",
        "    SELECT cf.*, p.predicted_diverted_probs[OFFSET(0)].prob AS score\n",
        "    FROM split cf\n",
        "    JOIN ML.PREDICT(MODEL `{MODEL_BASE}`,\n",
        "          (SELECT dep_delay, distance, carrier, origin, dest, EXTRACT(DAYOFWEEK FROM flight_date) AS day_of_week\n",
        "           FROM split)) AS p\n",
        "    ON TRUE\n",
        "    WHERE split='EVAL'\n",
        "  )\n",
        ")\n",
        "SELECT\n",
        "  SUM(CASE WHEN label=TRUE  AND pred_label=TRUE  THEN 1 ELSE 0 END) AS TP,\n",
        "  SUM(CASE WHEN label=FALSE AND pred_label=TRUE  THEN 1 ELSE 0 END) AS FP,\n",
        "  SUM(CASE WHEN label=TRUE  AND pred_label=FALSE THEN 1 ELSE 0 END) AS FN,\n",
        "  SUM(CASE WHEN label=FALSE AND pred_label=FALSE THEN 1 ELSE 0 END) AS TN\n",
        "FROM scored;\n",
        "'''\n",
        "bq.query(cm_thresh_sql).result().to_dataframe()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "003c38ee",
      "metadata": {
        "id": "003c38ee"
      },
      "source": [
        "\n",
        "## 4) Engineered model — `TRANSFORM` (same label, stricter bar)\n",
        "Create **route**, extract **day_of_week**, and **bucketize dep_delay**. Compare metrics to baseline.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec24def5",
      "metadata": {
        "id": "ec24def5"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "## Rubric (Flights, 100 pts)\n",
        "**Team-only deliverable in this notebook**\n",
        "\n",
        "- Baseline LOGISTIC_REG + evaluation (AUC + confusion @0.5) — **20**  \n",
        "- Custom threshold confusion matrix + ops justification — **20**  \n",
        "- Engineered model with `TRANSFORM` (route, DOW, delay bucket) — **20**  \n",
        "- Comparison table (baseline vs engineered) + 3–5 sentence interpretation — **20**  \n",
        "- Reproducibility: parameters clear, no hidden magic; schema mapping documented — **10**  \n",
        "- Governance notes: assumptions/limitations + slices you would monitor — **10**\n",
        "\n",
        "> **Strictness:** No screenshots; use actual results cells. Keep explanations concise (bullet points OK).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "089c680c"
      },
      "source": [
        "\n",
        "# Due to errors faced in template provided queries:\n",
        "\n",
        "Creating a new BigQuery table from flight data downloaded from a specified URL for a given year and month, and configuring the notebook's `TABLE_PATH` variable to use this new table for subsequent analysis."
      ],
      "id": "089c680c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a28bc288"
      },
      "source": [
        "## Downloading the Dataset\n"
      ],
      "id": "a28bc288"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72998a89"
      },
      "source": [
        "Downloading a `.zip` file to define the base URL, year, and month, construction the full download URL, and then using `wget` to download the file to the Colab environment.\n",
        "\n"
      ],
      "id": "72998a89"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2a576c76",
        "outputId": "191f630d-da4e-4eb4-d470-31227690a7c2"
      },
      "source": [
        "base_url = \"https://transtats.bts.gov/PREZIP/On_Time_Reporting_Carrier_On_Time_Performance_1987_present_{year}_{month}.zip\"\n",
        "year = 2023  # Example year\n",
        "month = 1    # Example month\n",
        "\n",
        "download_url = base_url.format(year=year, month=month)\n",
        "print(f\"Attempting to download from: {download_url}\")\n",
        "\n",
        "# Use wget to download the file\n",
        "!wget -nc {download_url}"
      ],
      "id": "2a576c76",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to download from: https://transtats.bts.gov/PREZIP/On_Time_Reporting_Carrier_On_Time_Performance_1987_present_2023_1.zip\n",
            "--2025-11-12 05:30:31--  https://transtats.bts.gov/PREZIP/On_Time_Reporting_Carrier_On_Time_Performance_1987_present_2023_1.zip\n",
            "Resolving transtats.bts.gov (transtats.bts.gov)... 204.68.194.70\n",
            "Connecting to transtats.bts.gov (transtats.bts.gov)|204.68.194.70|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27068766 (26M) [application/x-zip-compressed]\n",
            "Saving to: ‘On_Time_Reporting_Carrier_On_Time_Performance_1987_present_2023_1.zip’\n",
            "\n",
            "On_Time_Reporting_C 100%[===================>]  25.81M  1.47MB/s    in 18s     \n",
            "\n",
            "2025-11-12 05:30:50 (1.41 MB/s) - ‘On_Time_Reporting_Carrier_On_Time_Performance_1987_present_2023_1.zip’ saved [27068766/27068766]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1149cc5"
      },
      "source": [
        "Unzipping and extracting the contents of the zipped file to access the flight data.\n",
        "\n"
      ],
      "id": "a1149cc5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93be4501",
        "outputId": "7419e8c8-5d3c-479b-cdbd-ac03b2473bdd"
      },
      "source": [
        "import zipfile\n",
        "\n",
        "zip_file_name = f\"On_Time_Reporting_Carrier_On_Time_Performance_1987_present_{year}_{month}.zip\"\n",
        "with zipfile.ZipFile(zip_file_name, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\".\")\n",
        "print(f\"Extracted contents of {zip_file_name}\")"
      ],
      "id": "93be4501",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted contents of On_Time_Reporting_Carrier_On_Time_Performance_1987_present_2023_1.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce1836eb"
      },
      "source": [
        "Loading the extracted CSV file into a Pandas DataFrame to inspect its contents and ensure it's ready for upload to BigQuery. Confirming the correct CSV file name and its structure.\n",
        "\n"
      ],
      "id": "ce1836eb"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff42423c",
        "outputId": "50db5c51-6959-4307-fad0-6f81a64d8dab"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Construct the CSV file name based on the extracted zip content (from kernel state)\n",
        "csv_file_name = f\"On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_{year}_{month}.csv\"\n",
        "\n",
        "# Read the CSV file into a pandas DataFrame to inspect it\n",
        "df_flights = pd.read_csv(csv_file_name, low_memory=False)\n",
        "print(f\"Loaded {csv_file_name} into DataFrame. First 5 rows:\")\n",
        "print(df_flights.head())"
      ],
      "id": "ff42423c",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2023_1.csv into DataFrame. First 5 rows:\n",
            "   Year  Quarter  Month  DayofMonth  DayOfWeek  FlightDate Reporting_Airline  \\\n",
            "0  2023        1      1           2          1  2023-01-02                9E   \n",
            "1  2023        1      1           3          2  2023-01-03                9E   \n",
            "2  2023        1      1           4          3  2023-01-04                9E   \n",
            "3  2023        1      1           5          4  2023-01-05                9E   \n",
            "4  2023        1      1           6          5  2023-01-06                9E   \n",
            "\n",
            "   DOT_ID_Reporting_Airline IATA_CODE_Reporting_Airline Tail_Number  ...  \\\n",
            "0                     20363                          9E      N605LR  ...   \n",
            "1                     20363                          9E      N605LR  ...   \n",
            "2                     20363                          9E      N331PQ  ...   \n",
            "3                     20363                          9E      N906XJ  ...   \n",
            "4                     20363                          9E      N337PQ  ...   \n",
            "\n",
            "   Div4TailNum  Div5Airport  Div5AirportID  Div5AirportSeqID Div5WheelsOn  \\\n",
            "0          NaN          NaN            NaN               NaN          NaN   \n",
            "1          NaN          NaN            NaN               NaN          NaN   \n",
            "2          NaN          NaN            NaN               NaN          NaN   \n",
            "3          NaN          NaN            NaN               NaN          NaN   \n",
            "4          NaN          NaN            NaN               NaN          NaN   \n",
            "\n",
            "  Div5TotalGTime Div5LongestGTime  Div5WheelsOff Div5TailNum  Unnamed: 109  \n",
            "0            NaN              NaN            NaN         NaN           NaN  \n",
            "1            NaN              NaN            NaN         NaN           NaN  \n",
            "2            NaN              NaN            NaN         NaN           NaN  \n",
            "3            NaN              NaN            NaN         NaN           NaN  \n",
            "4            NaN              NaN            NaN         NaN           NaN  \n",
            "\n",
            "[5 rows x 110 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "323b1a28"
      },
      "source": [
        "Uploading the DataFrame to a new BigQuery table to make the data accessible for the subsequent BigQuery ML operations. The `TABLE_PATH` variable is updated to reflect this new table.\n",
        "\n"
      ],
      "id": "323b1a28"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92addecc",
        "outputId": "fe9e3517-945b-4c29-d25c-f531f564d2be"
      },
      "source": [
        "DATASET_ID = \"unit2_flights\"\n",
        "TABLE_ID = f\"flights_data_{year}_{month}\"\n",
        "\n",
        "# Create the dataset if it doesn't exist\n",
        "bigquery.Client(project=PROJECT_ID).create_dataset(DATASET_ID, exists_ok=True)\n",
        "\n",
        "# Upload the DataFrame to BigQuery\n",
        "df_flights.to_gbq(\n",
        "    destination_table=f\"{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}\",\n",
        "    project_id=PROJECT_ID,\n",
        "    if_exists='replace', # Replace table if it already exists\n",
        "    location=REGION\n",
        ")\n",
        "\n",
        "# Update TABLE_PATH to point to the new BigQuery table\n",
        "TABLE_PATH = f\"{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}\"\n",
        "\n",
        "print(f\"DataFrame uploaded to BigQuery table: {TABLE_PATH}\")"
      ],
      "id": "92addecc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1748041677.py:8: FutureWarning: to_gbq is deprecated and will be removed in a future version. Please use pandas_gbq.to_gbq instead: https://pandas-gbq.readthedocs.io/en/latest/api.html#pandas_gbq.to_gbq\n",
            "  df_flights.to_gbq(\n",
            "100%|██████████| 1/1 [00:00<00:00, 2030.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame uploaded to BigQuery table: mgmt-467-55510.unit2_flights.flights_data_2023_1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daeccc7b",
        "outputId": "6edeea97-af6e-4aa6-9fc7-74299b21c917"
      },
      "source": [
        "import pandas_gbq\n",
        "\n",
        "DATASET_ID = \"unit2_flights\"\n",
        "TABLE_ID = f\"flights_data_{year}_{month}\"\n",
        "\n",
        "# Create the dataset if it doesn't exist\n",
        "bigquery.Client(project=PROJECT_ID).create_dataset(DATASET_ID, exists_ok=True)\n",
        "\n",
        "# Upload the DataFrame to BigQuery\n",
        "pandas_gbq.to_gbq(\n",
        "    dataframe=df_flights,\n",
        "    destination_table=f\"{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}\",\n",
        "    project_id=PROJECT_ID,\n",
        "    if_exists='replace', # Replace table if it already exists\n",
        "    location=REGION\n",
        ")\n",
        "\n",
        "# Update TABLE_PATH to point to the new BigQuery table\n",
        "TABLE_PATH = f\"{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}\"\n",
        "\n",
        "print(f\"DataFrame uploaded to BigQuery table: {TABLE_PATH}\")"
      ],
      "id": "daeccc7b",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 9754.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame uploaded to BigQuery table: mgmt-467-55510.unit2_flights.flights_data_2023_1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ff1d5b2"
      },
      "source": [
        "The previous steps successfully uploaded the flight data to a new BigQuery table and updated the `TABLE_PATH` variable. The notebook's original flow included a quick sanity check that previously failed due to an incorrect `TABLE_PATH`. Now that the `TABLE_PATH` is correctly configured to the newly created table, the sanity check is re-run to confirm data accessibility.\n",
        "\n"
      ],
      "id": "2ff1d5b2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "492b5766",
        "outputId": "ae0e0a3b-0a6c-45f6-acd5-0542142ebb88"
      },
      "source": [
        "preview_sql = f\"SELECT * FROM `{TABLE_PATH}` LIMIT 5\"\n",
        "df = bq.query(preview_sql).to_dataframe()\n",
        "df.head()"
      ],
      "id": "492b5766",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Year  Quarter  Month  DayofMonth  DayOfWeek  FlightDate Reporting_Airline  \\\n",
              "0  2023        1      1           2          1  2023-01-02                9E   \n",
              "1  2023        1      1           3          2  2023-01-03                9E   \n",
              "2  2023        1      1           4          3  2023-01-04                9E   \n",
              "3  2023        1      1           5          4  2023-01-05                9E   \n",
              "4  2023        1      1           6          5  2023-01-06                9E   \n",
              "\n",
              "   DOT_ID_Reporting_Airline IATA_CODE_Reporting_Airline Tail_Number  ...  \\\n",
              "0                     20363                          9E      N601LR  ...   \n",
              "1                     20363                          9E      N910XJ  ...   \n",
              "2                     20363                          9E      N607LR  ...   \n",
              "3                     20363                          9E      N600LR  ...   \n",
              "4                     20363                          9E      N607LR  ...   \n",
              "\n",
              "   Div4TailNum  Div5Airport  Div5AirportID  Div5AirportSeqID Div5WheelsOn  \\\n",
              "0          NaN          NaN            NaN               NaN          NaN   \n",
              "1          NaN          NaN            NaN               NaN          NaN   \n",
              "2          NaN          NaN            NaN               NaN          NaN   \n",
              "3          NaN          NaN            NaN               NaN          NaN   \n",
              "4          NaN          NaN            NaN               NaN          NaN   \n",
              "\n",
              "  Div5TotalGTime Div5LongestGTime  Div5WheelsOff Div5TailNum  Unnamed: 109  \n",
              "0            NaN              NaN            NaN         NaN           NaN  \n",
              "1            NaN              NaN            NaN         NaN           NaN  \n",
              "2            NaN              NaN            NaN         NaN           NaN  \n",
              "3            NaN              NaN            NaN         NaN           NaN  \n",
              "4            NaN              NaN            NaN         NaN           NaN  \n",
              "\n",
              "[5 rows x 110 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e3420cfe-d9ee-47f8-b8a3-de49e6f71aa1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>Quarter</th>\n",
              "      <th>Month</th>\n",
              "      <th>DayofMonth</th>\n",
              "      <th>DayOfWeek</th>\n",
              "      <th>FlightDate</th>\n",
              "      <th>Reporting_Airline</th>\n",
              "      <th>DOT_ID_Reporting_Airline</th>\n",
              "      <th>IATA_CODE_Reporting_Airline</th>\n",
              "      <th>Tail_Number</th>\n",
              "      <th>...</th>\n",
              "      <th>Div4TailNum</th>\n",
              "      <th>Div5Airport</th>\n",
              "      <th>Div5AirportID</th>\n",
              "      <th>Div5AirportSeqID</th>\n",
              "      <th>Div5WheelsOn</th>\n",
              "      <th>Div5TotalGTime</th>\n",
              "      <th>Div5LongestGTime</th>\n",
              "      <th>Div5WheelsOff</th>\n",
              "      <th>Div5TailNum</th>\n",
              "      <th>Unnamed: 109</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2023</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2023-01-02</td>\n",
              "      <td>9E</td>\n",
              "      <td>20363</td>\n",
              "      <td>9E</td>\n",
              "      <td>N601LR</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2023</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2023-01-03</td>\n",
              "      <td>9E</td>\n",
              "      <td>20363</td>\n",
              "      <td>9E</td>\n",
              "      <td>N910XJ</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2023</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2023-01-04</td>\n",
              "      <td>9E</td>\n",
              "      <td>20363</td>\n",
              "      <td>9E</td>\n",
              "      <td>N607LR</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2023</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>2023-01-05</td>\n",
              "      <td>9E</td>\n",
              "      <td>20363</td>\n",
              "      <td>9E</td>\n",
              "      <td>N600LR</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2023</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>2023-01-06</td>\n",
              "      <td>9E</td>\n",
              "      <td>20363</td>\n",
              "      <td>9E</td>\n",
              "      <td>N607LR</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 110 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e3420cfe-d9ee-47f8-b8a3-de49e6f71aa1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e3420cfe-d9ee-47f8-b8a3-de49e6f71aa1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e3420cfe-d9ee-47f8-b8a3-de49e6f71aa1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8beff0d5-5a53-4f91-a9ff-cb3b755fabdb\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8beff0d5-5a53-4f91-a9ff-cb3b755fabdb')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8beff0d5-5a53-4f91-a9ff-cb3b755fabdb button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61f5edb1"
      },
      "source": [
        "Now, the new dataset is integrated and ready for further analysis within the notebook.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   The ontime flight data for January 2023 was successfully downloaded and extracted from `https://transtats.bts.gov/PREZIP/`.\n",
        "*   The extracted CSV file was loaded into a pandas DataFrame.\n",
        "*   The DataFrame was successfully uploaded to a new BigQuery table named `mgmt-467-55510.unit2_flights.flights_data_2023_1`.\n",
        "*   The notebook's `TABLE_PATH` variable was correctly updated to `mgmt-467-55510.unit2_flights.flights_data_2023_1`.\n",
        "*   A final sanity check confirmed that data could be successfully queried from the newly configured `TABLE_PATH`, displaying the first 5 rows of the new BigQuery table.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The dataset is now successfully integrated into BigQuery and configured for use, enabling subsequent data analysis directly from the notebook using the `TABLE_PATH` variable.\n"
      ],
      "id": "61f5edb1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ab92071"
      },
      "source": [
        "## Uploading CSV to GCS Bucket\n",
        "\n",
        "### Subtask:\n",
        "Uploading the locally extracted CSV file (e.g., `On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2023_1.csv`) to the specified Google Cloud Storage bucket: `gs://mgmt-467-55510-bts-flights-dataset`. This will prepare the data for loading into BigQuery from GCS.\n"
      ],
      "id": "0ab92071"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c1493de"
      },
      "source": [
        "\n",
        "First, the GCS bucket name and local CSV filename are defined using the existing `PROJECT_ID`, `year`, and `month` variables, and then the GCS bucket is created.\n",
        "\n"
      ],
      "id": "2c1493de"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9f6dcb5",
        "outputId": "63c1e366-63ea-4104-bd35-de6175f19d85"
      },
      "source": [
        "PROJECT_ID = \"mgmt-467-55510\"\n",
        "year = 2023\n",
        "month = 1\n",
        "\n",
        "GCS_BUCKET = f\"gs://{PROJECT_ID}-bts-flights-dataset\"\n",
        "GCS_REGION = \"us-central1\" # Specific region for GCS bucket creation\n",
        "\n",
        "# Create the GCS bucket\n",
        "# The -p flag sets the project, -l sets the location\n",
        "!gsutil mb -p {PROJECT_ID} -l {GCS_REGION} {GCS_BUCKET}\n",
        "\n",
        "# Construct the local CSV file name\n",
        "local_csv_file = f\"On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_{year}_{month}.csv\"\n",
        "\n",
        "print(f\"GCS Bucket set to: {GCS_BUCKET}\")\n",
        "print(f\"Local CSV file to upload: {local_csv_file}\")"
      ],
      "id": "c9f6dcb5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating gs://mgmt-467-55510-bts-flights-dataset/...\n",
            "You are attempting to access protected data with no configured\n",
            "credentials. Please visit https://cloud.google.com/console#/project\n",
            "and sign up for an account, and then run the \"gcloud auth login\"\n",
            "command to configure gsutil to use these credentials.\n",
            "GCS Bucket set to: gs://mgmt-467-55510-bts-flights-dataset\n",
            "Local CSV file to upload: On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2023_1.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f3a96c7"
      },
      "source": [
        "Uploading the local CSV file to the GCS bucket as specified in the subtask\n",
        "\n"
      ],
      "id": "8f3a96c7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b782849",
        "outputId": "b7f2d04e-bfd1-4fb8-f66c-4ba341ba1ad4"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user() # This typically authenticates for `google.cloud` client libraries\n",
        "\n",
        "# Explicitly authenticate gcloud application defaults for gsutil\n",
        "!gcloud auth application-default login\n",
        "\n",
        "# Retry the upload of the local CSV file to GCS\n",
        "gcs_csv_file = f\"{GCS_BUCKET}/{local_csv_file}\"\n",
        "!gsutil cp '{local_csv_file}' '{GCS_BUCKET}/'\n",
        "\n",
        "print(f\"Re-attempted upload of {local_csv_file} to {GCS_BUCKET}/\")"
      ],
      "id": "4b782849",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "You are running on a Google Compute Engine virtual machine.\n",
            "The service credentials associated with this virtual machine\n",
            "will automatically be used by Application Default\n",
            "Credentials, so it is not necessary to use this command.\n",
            "\n",
            "If you decide to proceed anyway, your user credentials may be visible\n",
            "to others with access to this virtual machine. Are you sure you want\n",
            "to authenticate with your personal account?\n",
            "\n",
            "Do you want to continue (Y/n)?  Y\n",
            "\n",
            "Go to the following link in your browser, and complete the sign-in prompts:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fsdk.cloud.google.com%2Fapplicationdefaultauthcode.html&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login&state=GUfnlcoltnsBVYUgLJSrNOtXYywYXG&prompt=consent&token_usage=remote&access_type=offline&code_challenge=JFzg5LxFnLf66JpLHX80ak5hUHKqjexNKdHwUzcF1UI&code_challenge_method=S256\n",
            "\n",
            "Once finished, enter the verification code provided in your browser: 4/0Ab32j90rEQd26-gC-CASKvZ1EduewTo9nqzKK9sWeG9iLq6mCnJYE2BEwL2w9kj8qFb5rw\n",
            "\n",
            "Credentials saved to file: [/content/.config/application_default_credentials.json]\n",
            "\n",
            "These credentials will be used by any library that requests Application Default Credentials (ADC).\n",
            "\u001b[1;33mWARNING:\u001b[0m \n",
            "Cannot find a quota project to add to ADC. You might receive a \"quota exceeded\" or \"API not enabled\" error. Run $ gcloud auth application-default set-quota-project to add a quota project.\n",
            "CommandException: No URLs matched: On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2023_1.csv\n",
            "Re-attempted upload of On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2023_1.csv to gs://mgmt-467-55510-bts-flights-dataset/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "653729d2"
      },
      "source": [
        "\n",
        "The 'CommandException: No URLs matched' error for the local file suggests that the `gsutil cp` command cannot find the specified CSV file in the current directory, despite previous steps indicating it was extracted and read. The `!ls -l` command is used to explicitly verify the existence of the local CSV file and confirm its exact filename and location.\n",
        "\n"
      ],
      "id": "653729d2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4190c38d",
        "outputId": "c071f38d-e195-4b4f-b59e-d1f741cdac24"
      },
      "source": [
        "print(f\"Verifying existence of local file: {local_csv_file}\")\n",
        "!ls -l '{local_csv_file}'"
      ],
      "id": "4190c38d",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Verifying existence of local file: On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2023_1.csv\n",
            "ls: cannot access 'On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2023_1.csv': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c93a67fa"
      },
      "source": [
        "\n",
        "The `!ls -l` command indicated that the previously assumed `local_csv_file` does not exist. To accurately identify the CSV file extracted from the zip archive, all files in the current directory can be listed in order to find the actual CSV file name.\n",
        "\n"
      ],
      "id": "c93a67fa"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bd2d163",
        "outputId": "646322ad-17ab-4118-e767-63d1d2e10590"
      },
      "source": [
        "print(\"Listing all files in the current directory to find the CSV file:\")\n",
        "!ls -F"
      ],
      "id": "0bd2d163",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Listing all files in the current directory to find the CSV file:\n",
            "sample_data/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0529422b"
      },
      "source": [
        "\n",
        "The previous `!ls -l` and `!ls -F` commands confirmed that the CSV file is no longer present in the local directory, despite it being successfully loaded into a DataFrame earlier. This suggests a possible environment reset or file deletion. To ensure the CSV file exists for upload to GCS, the download and extraction steps are re-run.\n",
        "\n"
      ],
      "id": "0529422b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3f91889",
        "outputId": "0869c3d3-bb04-4dcb-d8f1-fd7b5ceacc59"
      },
      "source": [
        "base_url = \"https://transtats.bts.gov/PREZIP/On_Time_Reporting_Carrier_On_Time_Performance_1987_present_{year}_{month}.zip\"\n",
        "year = 2023\n",
        "month = 1\n",
        "\n",
        "download_url = base_url.format(year=year, month=month)\n",
        "print(f\"Re-downloading from: {download_url}\")\n",
        "\n",
        "# Use wget to download the file (using -nc to avoid re-downloading if already present)\n",
        "!wget -nc {download_url}\n",
        "\n",
        "import zipfile\n",
        "zip_file_name = f\"On_Time_Reporting_Carrier_On_Time_Performance_1987_present_{year}_{month}.zip\"\n",
        "with zipfile.ZipFile(zip_file_name, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\".\")\n",
        "print(f\"Re-extracted contents of {zip_file_name}\")\n",
        "\n",
        "# Re-define local_csv_file after re-extraction\n",
        "local_csv_file = f\"On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_{year}_{month}.csv\"\n",
        "print(f\"Local CSV file re-confirmed as: {local_csv_file}\")"
      ],
      "id": "a3f91889",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Re-downloading from: https://transtats.bts.gov/PREZIP/On_Time_Reporting_Carrier_On_Time_Performance_1987_present_2023_1.zip\n",
            "--2025-11-08 21:04:56--  https://transtats.bts.gov/PREZIP/On_Time_Reporting_Carrier_On_Time_Performance_1987_present_2023_1.zip\n",
            "Resolving transtats.bts.gov (transtats.bts.gov)... 204.68.194.70\n",
            "Connecting to transtats.bts.gov (transtats.bts.gov)|204.68.194.70|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27068766 (26M) [application/x-zip-compressed]\n",
            "Saving to: ‘On_Time_Reporting_Carrier_On_Time_Performance_1987_present_2023_1.zip’\n",
            "\n",
            "On_Time_Reporting_C 100%[===================>]  25.81M  2.98MB/s    in 9.1s    \n",
            "\n",
            "2025-11-08 21:05:05 (2.85 MB/s) - ‘On_Time_Reporting_Carrier_On_Time_Performance_1987_present_2023_1.zip’ saved [27068766/27068766]\n",
            "\n",
            "Re-extracted contents of On_Time_Reporting_Carrier_On_Time_Performance_1987_present_2023_1.zip\n",
            "Local CSV file re-confirmed as: On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2023_1.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eca3a081"
      },
      "source": [
        "Retrying uploading of the CSV file to the GCS bucket using the `gsutil cp` command with proper quoting to handle special characters in the filename.\n",
        "\n"
      ],
      "id": "eca3a081"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "797e07c9",
        "outputId": "a8b22277-9f5a-4b7d-cd91-f67c57451f96"
      },
      "source": [
        "gcs_csv_file = f\"{GCS_BUCKET}/{local_csv_file}\"\n",
        "!gsutil cp '{local_csv_file}' '{GCS_BUCKET}/'\n",
        "\n",
        "print(f\"Successfully re-uploaded {local_csv_file} to {GCS_BUCKET}/\")"
      ],
      "id": "797e07c9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying file://On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2023_1.csv [Content-Type=text/csv]...\n",
            "/ [0 files][    0.0 B/232.1 MiB]                                                \r==> NOTE: You are uploading one or more large file(s), which would run\n",
            "significantly faster if you enable parallel composite uploads. This\n",
            "feature can be enabled by editing the\n",
            "\"parallel_composite_upload_threshold\" value in your .boto\n",
            "configuration file. However, note that if you do this large files will\n",
            "be uploaded as `composite objects\n",
            "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
            "means that any user who downloads such objects will need to have a\n",
            "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
            "without a compiled crcmod, computing checksums on composite objects is\n",
            "so slow that gsutil disables downloads of composite objects.\n",
            "\n",
            "/\n",
            "Operation completed over 1 objects/232.1 MiB.                                    \n",
            "Successfully re-uploaded On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2023_1.csv to gs://mgmt-467-55510-bts-flights-dataset/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bc2e173"
      },
      "source": [
        "A new BigQuery table is created by loading data from this GCS path. This involves defining the new BigQuery table ID and using the `bigquery.Client` to load the data.\n",
        "\n"
      ],
      "id": "3bc2e173"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08f62207",
        "outputId": "1a4ad7fd-9798-4ef6-d833-56b3272ea18e"
      },
      "source": [
        "import os\n",
        "from google.cloud import bigquery\n",
        "import pandas as pd\n",
        "from google.cloud.bigquery import SchemaField # Import SchemaField for manual schema definition\n",
        "\n",
        "PROJECT_ID = \"mgmt-467-55510\" # Re-define PROJECT_ID for self-contained execution\n",
        "REGION = \"us\" # Re-define REGION\n",
        "bq = bigquery.Client(project=PROJECT_ID) # Re-initialize bq client\n",
        "\n",
        "# These variables need to be defined from previous successful steps or kernel state\n",
        "year = 2023\n",
        "month = 1\n",
        "DATASET_ID = \"unit2_flights\"\n",
        "GCS_BUCKET = f\"gs://{PROJECT_ID}-bts-flights-dataset\" # Re-construct GCS_BUCKET from PROJECT_ID\n",
        "\n",
        "TABLE_ID_GCS = f\"flights_data_{year}_{month}_from_gcs\"\n",
        "DESTINATION_TABLE_PATH = f\"{PROJECT_ID}.{DATASET_ID}.{TABLE_ID_GCS}\"\n",
        "\n",
        "local_csv_file = f\"On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_{year}_{month}.csv\"\n",
        "\n",
        "# Re-read the CSV into df_flights to ensure it's available and fresh for schema generation\n",
        "df_flights = pd.read_csv(local_csv_file, low_memory=False)\n",
        "\n",
        "# Generate schema from the pandas DataFrame by iterating through dtypes\n",
        "bq_schema = []\n",
        "for column, dtype in df_flights.dtypes.items():\n",
        "    if pd.api.types.is_integer_dtype(dtype):\n",
        "        field_type = 'INTEGER'\n",
        "    elif pd.api.types.is_float_dtype(dtype):\n",
        "        field_type = 'FLOAT'\n",
        "    elif pd.api.types.is_bool_dtype(dtype):\n",
        "        field_type = 'BOOLEAN'\n",
        "    elif pd.api.types.is_datetime64_any_dtype(dtype):\n",
        "        field_type = 'TIMESTAMP' # Assuming datetime columns can be TIMESTAMP\n",
        "    elif pd.api.types.is_object_dtype(dtype) or pd.api.types.is_string_dtype(dtype):\n",
        "        field_type = 'STRING'\n",
        "    else: # Fallback for other types, e.g., categorical, mixed, treat as STRING\n",
        "        field_type = 'STRING'\n",
        "    bq_schema.append(SchemaField(column, field_type, mode='NULLABLE')) # Most fields are nullable by default\n",
        "\n",
        "# Configure the job for loading data from GCS\n",
        "job_config = bigquery.LoadJobConfig(\n",
        "    schema=bq_schema, # Provide the manually generated schema\n",
        "    source_format=bigquery.SourceFormat.CSV,\n",
        "    skip_leading_rows=1,  # Skip header row\n",
        "    # autodetect=True, # No longer needed with explicit schema\n",
        ")\n",
        "\n",
        "gcs_uri = f\"{GCS_BUCKET}/{local_csv_file}\"\n",
        "\n",
        "# Load data from GCS to BigQuery\n",
        "load_job = bq.load_table_from_uri(\n",
        "    gcs_uri,\n",
        "    DESTINATION_TABLE_PATH,\n",
        "    job_config=job_config,\n",
        ")\n",
        "\n",
        "load_job.result()  # Waits for the job to complete\n",
        "\n",
        "print(f\"Loaded {load_job.output_rows} rows into {DESTINATION_TABLE_PATH} from GCS.\")\n",
        "\n",
        "# Update TABLE_PATH to point to the new BigQuery table from GCS\n",
        "TABLE_PATH = DESTINATION_TABLE_PATH\n",
        "\n",
        "print(f\"TABLE_PATH updated to: {TABLE_PATH}\")"
      ],
      "id": "08f62207",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/google/auth/_default.py:76: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
            "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 538837 rows into mgmt-467-55510.unit2_flights.flights_data_2023_1_from_gcs from GCS.\n",
            "TABLE_PATH updated to: mgmt-467-55510.unit2_flights.flights_data_2023_1_from_gcs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dc16cdb"
      },
      "source": [
        "\n",
        "Correcting the SQL query in cell `308e3518` for the default threshold confusion matrix. The current query has a syntax error. The fix will ensure the query correctly calculates True Positives, False Positives, False Negatives, and True Negatives by properly referencing the `split` CTE and `ML.PREDICT` output.\n"
      ],
      "id": "4dc16cdb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline model — LOGISTIC_REG (`diverted`)\n",
        "Use **only** a small set of signals for the baseline (keep it honest)."
      ],
      "metadata": {
        "id": "UintAsvbPfMA"
      },
      "id": "UintAsvbPfMA"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "b9b9617b",
        "outputId": "4f05a1d9-3929-403d-9565-6a14559bf540"
      },
      "source": [
        "PROJECT_ID = \"mgmt-467-55510\"\n",
        "TABLE_PATH = \"mgmt-467-55510.unit2_flights.flights_data_2023_1_from_gcs\" # Current TABLE_PATH from kernel state\n",
        "\n",
        "CANONICAL_BASE_SQL = f'''\n",
        "WITH canonical_flights AS (\n",
        "  SELECT\n",
        "    CAST(FlightDate AS DATE) AS flight_date,\n",
        "    CAST(DepDelay AS FLOAT64) AS dep_delay,\n",
        "    CAST(distance  AS FLOAT64) AS distance,\n",
        "    CAST(Reporting_Airline   AS STRING)  AS carrier,\n",
        "    CAST(Origin    AS STRING)  AS origin,\n",
        "    CAST(Dest AS STRING) AS dest,\n",
        "    CAST((CASE WHEN SAFE_CAST(Diverted AS INT64)=1 OR LOWER(CAST(Diverted AS STRING))='true' THEN TRUE ELSE FALSE END) AS BOOL) AS diverted\n",
        "  FROM `{TABLE_PATH}`\n",
        "  WHERE DepDelay IS NOT NULL\n",
        ")\n",
        "'''\n",
        "\n",
        "SPLIT_CLAUSE = r'''\n",
        ", split AS (\n",
        "  SELECT cf.*,\n",
        "         CASE WHEN RAND() < 0.8 THEN 'TRAIN' ELSE 'EVAL' END AS split\n",
        "  FROM canonical_flights cf\n",
        ")\n",
        "'''\n",
        "\n",
        "MODEL_BASE = f\"{PROJECT_ID}.unit2_flights.clf_diverted_base\"\n",
        "\n",
        "cm_default_sql = f'''\n",
        "{CANONICAL_BASE_SQL}\n",
        "{SPLIT_CLAUSE}\n",
        "\n",
        ", predictions AS (\n",
        "  SELECT * FROM ML.PREDICT(\n",
        "    MODEL `{MODEL_BASE}`,\n",
        "    (SELECT\n",
        "       s.diverted, -- Include the true label for comparison\n",
        "       s.dep_delay,\n",
        "       s.distance,\n",
        "       s.carrier,\n",
        "       s.origin,\n",
        "       s.dest,\n",
        "       EXTRACT(DAYOFWEEK FROM s.flight_date) AS day_of_week\n",
        "     FROM split AS s\n",
        "     WHERE s.split='EVAL')\n",
        "  )\n",
        "),\n",
        "scored AS (\n",
        "  SELECT\n",
        "    diverted AS label, -- This is the original label passed through ML.PREDICT\n",
        "    predicted_diverted AS pred_label,\n",
        "    predicted_diverted_probs[OFFSET(0)].prob AS score\n",
        "  FROM predictions\n",
        ")\n",
        "SELECT\n",
        "  SUM(CASE WHEN label=TRUE  AND pred_label=TRUE  THEN 1 ELSE 0 END) AS TP,\n",
        "  SUM(CASE WHEN label=FALSE AND pred_label=TRUE  THEN 1 ELSE 0 END) AS FP,\n",
        "  SUM(CASE WHEN label=TRUE  AND pred_label=FALSE THEN 1 ELSE 0 END) AS FN,\n",
        "  SUM(CASE WHEN label=FALSE AND pred_label=FALSE THEN 1 ELSE 0 END) AS TN\n",
        "FROM scored;\n",
        "'''\n",
        "bq.query(cm_default_sql).result().to_dataframe()\n"
      ],
      "id": "b9b9617b",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   TP  FP   FN      TN\n",
              "0   0   0  256  105184"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-55048098-d2b7-478e-b7fa-2b94ebb7d587\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TP</th>\n",
              "      <th>FP</th>\n",
              "      <th>FN</th>\n",
              "      <th>TN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>256</td>\n",
              "      <td>105184</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-55048098-d2b7-478e-b7fa-2b94ebb7d587')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-55048098-d2b7-478e-b7fa-2b94ebb7d587 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-55048098-d2b7-478e-b7fa-2b94ebb7d587');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"bq\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"TP\",\n      \"properties\": {\n        \"dtype\": \"Int64\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FP\",\n      \"properties\": {\n        \"dtype\": \"Int64\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FN\",\n      \"properties\": {\n        \"dtype\": \"Int64\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          256\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TN\",\n      \"properties\": {\n        \"dtype\": \"Int64\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          105184\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b369ab4"
      },
      "source": [
        "\n",
        "The previous fix for `cm_default_sql` involved restructuring the `ML.PREDICT` call and its integration with CTEs. A similar fix to `cm_thresh_sql` can be applied to correctly calculate the confusion matrix with a custom threshold. This involves using a `predictions` CTE to encapsulate the `ML.PREDICT` output and then a `scored` CTE to apply the custom threshold before calculating TP, FP, FN, TN.\n",
        "\n"
      ],
      "id": "1b369ab4"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "aae9d273",
        "outputId": "699ae30d-361b-497c-f457-5e17f8f65779"
      },
      "source": [
        "CUSTOM_THRESHOLD = 0.75  # TODO: justify in ops terms\n",
        "\n",
        "cm_thresh_sql = f'''\n",
        "{CANONICAL_BASE_SQL}\n",
        "{SPLIT_CLAUSE}\n",
        "\n",
        ", predictions AS (\n",
        "  SELECT * FROM ML.PREDICT(\n",
        "    MODEL `{MODEL_BASE}`,\n",
        "    (SELECT\n",
        "       s.diverted, -- Include the true label for comparison\n",
        "       s.dep_delay,\n",
        "       s.distance,\n",
        "       s.carrier,\n",
        "       s.origin,\n",
        "       s.dest,\n",
        "       EXTRACT(DAYOFWEEK FROM s.flight_date) AS day_of_week\n",
        "     FROM split AS s\n",
        "     WHERE s.split='EVAL')\n",
        "  )\n",
        "),\n",
        "scored AS (\n",
        "  SELECT\n",
        "    diverted AS label, -- This is the original label passed through ML.PREDICT\n",
        "    CAST(predicted_diverted_probs[OFFSET(0)].prob >= {CUSTOM_THRESHOLD} AS BOOL) AS pred_label\n",
        "  FROM predictions\n",
        ")\n",
        "SELECT\n",
        "  SUM(CASE WHEN label=TRUE  AND pred_label=TRUE  THEN 1 ELSE 0 END) AS TP,\n",
        "  SUM(CASE WHEN label=FALSE AND pred_label=TRUE  THEN 1 ELSE 0 END) AS FP,\n",
        "  SUM(CASE WHEN label=TRUE  AND pred_label=FALSE THEN 1 ELSE 0 END) AS FN,\n",
        "  SUM(CASE WHEN label=FALSE AND pred_label=FALSE THEN 1 ELSE 0 END) AS TN\n",
        "FROM scored;\n",
        "'''\n",
        "bq.query(cm_thresh_sql).result().to_dataframe()\n"
      ],
      "id": "aae9d273",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   TP  FP   FN      TN\n",
              "0   0   0  270  105264"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-43a2e0c1-74da-4b02-8294-4633da6ded2e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TP</th>\n",
              "      <th>FP</th>\n",
              "      <th>FN</th>\n",
              "      <th>TN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>270</td>\n",
              "      <td>105264</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-43a2e0c1-74da-4b02-8294-4633da6ded2e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-43a2e0c1-74da-4b02-8294-4633da6ded2e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-43a2e0c1-74da-4b02-8294-4633da6ded2e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"bq\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"TP\",\n      \"properties\": {\n        \"dtype\": \"Int64\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FP\",\n      \"properties\": {\n        \"dtype\": \"Int64\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FN\",\n      \"properties\": {\n        \"dtype\": \"Int64\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          270\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TN\",\n      \"properties\": {\n        \"dtype\": \"Int64\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          105264\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59c59a86"
      },
      "source": [
        "\n",
        "The overall task requires re-executing the baseline model training (cell `bac26b12`) after the `TABLE_PATH` has been updated and before computing the confusion matrices or training the engineered model. This ensures the baseline model is trained on the newly configured BigQuery table.\n",
        "\n"
      ],
      "id": "59c59a86"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df945eb0",
        "outputId": "108560d1-9e16-43cf-da81-dbd30cacac26"
      },
      "source": [
        "MODEL_BASE = f\"{PROJECT_ID}.unit2_flights.clf_diverted_base\"\n",
        "\n",
        "# Create schema\n",
        "sql_create_schema = f\"CREATE SCHEMA IF NOT EXISTS `{PROJECT_ID}.unit2_flights`;\"\n",
        "job = bq.query(sql_create_schema); _ = job.result()\n",
        "print(f\"Schema created/verified: {PROJECT_ID}.unit2_flights\")\n",
        "\n",
        "# Construct the training data query with CTEs\n",
        "sql_training_query = f'''\n",
        "{CANONICAL_BASE_SQL}\n",
        "{SPLIT_CLAUSE}\n",
        "SELECT\n",
        "  s.diverted,\n",
        "  s.dep_delay, s.distance, s.carrier, s.origin, s.dest,\n",
        "  EXTRACT(DAYOFWEEK FROM s.flight_date) AS day_of_week\n",
        "FROM split AS s\n",
        "WHERE s.split='TRAIN'\n",
        "'''\n",
        "\n",
        "# Create model using the constructed training query\n",
        "sql_create_model = f'''\n",
        "CREATE OR REPLACE MODEL `{MODEL_BASE}`\n",
        "OPTIONS (MODEL_TYPE='LOGISTIC_REG', INPUT_LABEL_COLS=['diverted']) AS\n",
        "{sql_training_query}\n",
        ";\n",
        "'''\n",
        "job = bq.query(sql_create_model); _ = job.result()\n",
        "print(\"Baseline model trained:\", MODEL_BASE)\n",
        "\n",
        "# For evaluation, we combine the CTEs and the EVALUATE statement.\n",
        "sql_full_evaluate = f'''\n",
        "{CANONICAL_BASE_SQL}\n",
        "{SPLIT_CLAUSE}\n",
        "\n",
        "SELECT * FROM ML.EVALUATE(\n",
        "  MODEL `{MODEL_BASE}`,\n",
        "  (SELECT\n",
        "     s.diverted,\n",
        "     s.dep_delay, s.distance, s.carrier, s.origin, s.dest,\n",
        "     EXTRACT(DAYOFWEEK FROM s.flight_date) AS day_of_week\n",
        "   FROM split AS s WHERE s.split='EVAL')\n",
        ");\n",
        "'''\n",
        "evaluation_df = bq.query(sql_full_evaluate).to_dataframe()\n",
        "print(\"Baseline model evaluation results:\")\n",
        "print(evaluation_df)\n"
      ],
      "id": "df945eb0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Schema created/verified: mgmt-467-55510.unit2_flights\n",
            "Baseline model trained: mgmt-467-55510.unit2_flights.clf_diverted_base\n",
            "Baseline model evaluation results:\n",
            "   precision  recall  accuracy  f1_score  log_loss   roc_auc\n",
            "0        0.0     0.0  0.997446       0.0    0.0162  0.800851\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12e19b8c"
      },
      "source": [
        "**Reasoning**:\n",
        "The next step in the task is to train and evaluate the engineered model using the `TRANSFORM` clause, comparing its metrics to the baseline model. I will execute the content of cell `0cc51f09` which handles this process.\n",
        "\n"
      ],
      "id": "12e19b8c"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Engineered model — `TRANSFORM` (same label, stricter bar)\n",
        "Create **route**, extract **day_of_week**, and **bucketize dep_delay**. Compare metrics to baseline.\n"
      ],
      "metadata": {
        "id": "HEartIYVP1D-"
      },
      "id": "HEartIYVP1D-"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df201838",
        "outputId": "6d542d34-da9d-4efa-86e0-f410522372e8"
      },
      "source": [
        "MODEL_XFORM = f\"{PROJECT_ID}.unit2_flights.clf_diverted_xform\"\n",
        "\n",
        "# Update SPLIT_CLAUSE to explicitly list columns\n",
        "# Note: This SPLIT_CLAUSE is only used if explicitly referenced like {SPLIT_CLAUSE},\n",
        "# but we are embedding the full CTEs directly into the model creation/evaluation queries.\n",
        "# This variable itself is not strictly necessary anymore for this cell but is kept for consistency.\n",
        "SPLIT_CLAUSE = r'''\n",
        ", split AS (\n",
        "  SELECT\n",
        "    cf.flight_date,\n",
        "    cf.dep_delay,\n",
        "    cf.distance,\n",
        "    cf.carrier,\n",
        "    cf.origin,\n",
        "    cf.dest,\n",
        "    cf.diverted,\n",
        "    CASE WHEN RAND() < 0.8 THEN 'TRAIN' ELSE 'EVAL' END AS data_split_col\n",
        "  FROM canonical_flights cf\n",
        ")\n",
        "'''\n",
        "\n",
        "sql_create_xform_model = f'''\n",
        "CREATE OR REPLACE MODEL `{MODEL_XFORM}`\n",
        "TRANSFORM (\n",
        "  CONCAT(origin, '-', dest) AS route,\n",
        "  EXTRACT(DAYOFWEEK FROM flight_date) AS day_of_week,\n",
        "  CASE\n",
        "    WHEN dep_delay < -5  THEN 'early'\n",
        "    WHEN dep_delay <=  5 THEN 'on_time'\n",
        "    WHEN dep_delay <= 15 THEN 'minor'\n",
        "    WHEN dep_delay <= 45 THEN 'moderate'\n",
        "    ELSE 'major'\n",
        "  END AS dep_delay_bucket,\n",
        "  dep_delay, distance, carrier, origin, dest,\n",
        "  diverted -- Ensure the label column is part of the TRANSFORM output\n",
        ")\n",
        "OPTIONS (MODEL_TYPE='LOGISTIC_REG', INPUT_LABEL_COLS=['diverted']) AS\n",
        "WITH canonical_flights AS (\n",
        "  SELECT\n",
        "    CAST(FlightDate AS DATE) AS flight_date,\n",
        "    CAST(DepDelay AS FLOAT64) AS dep_delay,\n",
        "    CAST(distance  AS FLOAT64) AS distance,\n",
        "    CAST(Reporting_Airline   AS STRING)  AS carrier,\n",
        "    CAST(Origin    AS STRING)  AS origin,\n",
        "    CAST(Dest AS STRING) AS dest,\n",
        "    CAST((CASE WHEN SAFE_CAST(Diverted AS INT64)=1 OR LOWER(CAST(Diverted AS STRING))='true' THEN TRUE ELSE FALSE END) AS BOOL) AS diverted\n",
        "  FROM `{TABLE_PATH}`\n",
        "  WHERE DepDelay IS NOT NULL\n",
        "),\n",
        "split AS (\n",
        "  SELECT\n",
        "    cf.flight_date,\n",
        "    cf.dep_delay,\n",
        "    cf.distance,\n",
        "    cf.carrier,\n",
        "    cf.origin,\n",
        "    cf.dest,\n",
        "    cf.diverted,\n",
        "    CASE WHEN RAND() < 0.8 THEN 'TRAIN' ELSE 'EVAL' END AS data_split_col\n",
        "  FROM canonical_flights cf\n",
        ")\n",
        "SELECT * FROM split WHERE data_split_col='TRAIN'\n",
        ";\n",
        "'''\n",
        "\n",
        "job = bq.query(sql_create_xform_model); _ = job.result()\n",
        "print(\"Engineered model trained:\", MODEL_XFORM)\n",
        "\n",
        "sql_evaluate_xform_models = f'''\n",
        "WITH canonical_flights AS (\n",
        "  SELECT\n",
        "    CAST(FlightDate AS DATE) AS flight_date,\n",
        "    CAST(DepDelay AS FLOAT64) AS dep_delay,\n",
        "    CAST(distance  AS FLOAT64) AS distance,\n",
        "    CAST(Reporting_Airline   AS STRING)  AS carrier,\n",
        "    CAST(Origin    AS STRING)  AS origin,\n",
        "    CAST(Dest AS STRING) AS dest,\n",
        "    CAST((CASE WHEN SAFE_CAST(Diverted AS INT64)=1 OR LOWER(CAST(Diverted AS STRING))='true' THEN TRUE ELSE FALSE END) AS BOOL) AS diverted\n",
        "  FROM `{TABLE_PATH}`\n",
        "  WHERE DepDelay IS NOT NULL\n",
        "),\n",
        "split AS (\n",
        "  SELECT\n",
        "    cf.flight_date,\n",
        "    cf.dep_delay,\n",
        "    cf.distance,\n",
        "    cf.carrier,\n",
        "    cf.origin,\n",
        "    cf.dest,\n",
        "    cf.diverted,\n",
        "    CASE WHEN RAND() < 0.8 THEN 'TRAIN' ELSE 'EVAL' END AS data_split_col\n",
        "  FROM canonical_flights cf\n",
        ")\n",
        "SELECT 'baseline' AS model_version, * FROM ML.EVALUATE(\n",
        "  MODEL `{MODEL_BASE}`,\n",
        "  (SELECT\n",
        "     diverted,\n",
        "     dep_delay, distance, carrier, origin, dest,\n",
        "     EXTRACT(DAYOFWEEK FROM flight_date) AS day_of_week\n",
        "   FROM split WHERE data_split_col='EVAL')\n",
        ")\n",
        "UNION ALL\n",
        "SELECT 'engineered' AS model_version, * FROM ML.EVALUATE(\n",
        "  MODEL `{MODEL_XFORM}`,\n",
        "  (SELECT * FROM split WHERE data_split_col='EVAL')\n",
        ");\n",
        "'''\n",
        "\n",
        "evaluation_xform_df = bq.query(sql_evaluate_xform_models).to_dataframe()\n",
        "print(\"Engineered model evaluation results vs baseline:\")\n",
        "print(evaluation_xform_df)\n"
      ],
      "id": "df201838",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Engineered model trained: mgmt-467-55510.unit2_flights.clf_diverted_xform\n",
            "Engineered model evaluation results vs baseline:\n",
            "  model_version  precision    recall  accuracy  f1_score  log_loss   roc_auc\n",
            "0    engineered       0.25  0.017668  0.997241  0.033003  0.015694  0.892322\n",
            "1      baseline       0.00  0.000000  0.997733  0.000000  0.014448  0.800841\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f36b655"
      },
      "source": [
        "# Performance Limitations (Diverted Prediction)\n",
        "\n",
        "The primary limitation is severe class imbalance for the diverted class, leading to models that favor the majority class:\n",
        "\n",
        "  *  High Accuracy Masking Failure: Overall accuracy is high (Baseline: 0.997446; Engineered: 0.997241), but this masks the poor performance on the minority class.\n",
        "\n",
        "   *  Near-Zero True Positives (TP): The Baseline model produced 0 TP at both the default (0.5) and custom (0.75) thresholds, resulting in high False Negatives (FN: 256 and 270 respectively).\n",
        "\n",
        "  *   Engineered Model Improvement but Low Recall: The Engineered model's AUC improved significantly (0.892322 vs. 0.800851), but recall remained very low (0.017668) with precision at 0.25.\n",
        "\n",
        "   *  Ineffective Thresholds: The standard thresholds of 0.5 and 0.75 are too high, consistently missing true positive cases.\n",
        "\n",
        "\n",
        "Key Learnings & Next Steps\n",
        "\n",
        "   * BQML Proficiency: Established robust data handling (gsutil, schema definitions) and BQML syntax proficiency for model training (LOGISTIC_REG, TRANSFORM), evaluation, and data splitting.\n",
        "\n",
        "   * Priority Challenge: The severe class imbalance must be addressed beyond simple threshold tuning.\n",
        "\n",
        "   * Operational Focus: Since diversions are costly, achieving a non-zero TP rate is critical. Next steps must focus on:\n",
        "\n",
        "      *  Investigating probability distributions to find a highly effective, lower deployment threshold.\n",
        "\n",
        "       * Re-evaluating the business cost balance between False Negatives (missed diversion warnings) and False Positives (false alarms) to justify aggressive class imbalance techniques."
      ],
      "id": "8f36b655"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c001f123"
      },
      "source": [
        "# **Required Scope**\n",
        "A comprehensive summary of all the key findings from the notebook. This summary includes:\n",
        "*   A comparison of the performance between the baseline and engineered models (e.g., AUC, precision, recall).\n",
        "*   Insights gained from feature engineering using the `TRANSFORM` clause.\n",
        "*   The proposed strategies for threshold selection, addressing the lack of true positives, and their operational justification.\n",
        "*   Discussion on cost and scale considerations for model development and deployment, including strategies for development iterations and final model runs."
      ],
      "id": "c001f123"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cc6c9259"
      },
      "source": [
        "## Training Regression Model (arr_delay)\n",
        "\n",
        "Training a BigQuery ML `LINEAR_REG` model to predict `arr_delay` using at least five features.\n"
      ],
      "id": "cc6c9259"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e788d5b",
        "outputId": "520493a6-d7d0-41f1-c213-be78b46e1261"
      },
      "source": [
        "import os\n",
        "from google.colab import auth\n",
        "from google.cloud import bigquery\n",
        "\n",
        "# Re-authenticate to Google\n",
        "auth.authenticate_user()\n",
        "\n",
        "PROJECT_ID = \"mgmt-467-55510\" # Re-define PROJECT_ID for self-contained execution\n",
        "REGION = \"us\" # Re-define REGION\n",
        "bq = bigquery.Client(project=PROJECT_ID) # Re-initialize bq client\n",
        "TABLE_PATH = \"mgmt-467-55510.unit2_flights.flights_data_2023_1_from_gcs\" # Define TABLE_PATH from kernel state\n",
        "\n",
        "MODEL_REG = f\"{PROJECT_ID}.unit2_flights.clf_arr_delay_reg\"\n",
        "\n",
        "# Redefine CANONICAL_BASE_SQL to include arr_delay for the regression model\n",
        "# This temporary definition is for this cell's specific requirements.\n",
        "CANONICAL_BASE_SQL_REG = f'''\n",
        "WITH canonical_flights AS (\n",
        "  SELECT\n",
        "    CAST(FlightDate AS DATE) AS flight_date,\n",
        "    CAST(DepDelay AS FLOAT64) AS dep_delay,\n",
        "    CAST(ArrDelay AS FLOAT64) AS arr_delay, -- Added arr_delay as a feature/label\n",
        "    CAST(distance  AS FLOAT64) AS distance,\n",
        "    CAST(Reporting_Airline   AS STRING)  AS carrier,\n",
        "    CAST(Origin    AS STRING)  AS origin,\n",
        "    CAST(Dest AS STRING) AS dest,\n",
        "    CAST((CASE WHEN SAFE_CAST(Diverted AS INT64)=1 OR LOWER(CAST(Diverted AS STRING))='true' THEN TRUE ELSE FALSE END) AS BOOL) AS diverted\n",
        "  FROM `{TABLE_PATH}`\n",
        "  WHERE DepDelay IS NOT NULL AND ArrDelay IS NOT NULL -- Filter for non-null arr_delay for regression\n",
        ")\n",
        "'''\n",
        "\n",
        "# Using the split clause from cell df201838, ensuring it includes arr_delay and uses data_split_col\n",
        "SPLIT_CLAUSE_REG = r'''\n",
        ", split AS (\n",
        "  SELECT\n",
        "    cf.flight_date,\n",
        "    cf.dep_delay,\n",
        "    cf.arr_delay,\n",
        "    cf.distance,\n",
        "    cf.carrier,\n",
        "    cf.origin,\n",
        "    cf.dest,\n",
        "    cf.diverted,\n",
        "    CASE WHEN RAND() < 0.8 THEN 'TRAIN' ELSE 'EVAL' END AS data_split_col\n",
        "  FROM canonical_flights cf\n",
        ")\n",
        "'''\n",
        "\n",
        "sql_create_reg_model = f'''\n",
        "CREATE OR REPLACE MODEL `{MODEL_REG}`\n",
        "OPTIONS (\n",
        "  MODEL_TYPE='LINEAR_REG',\n",
        "  INPUT_LABEL_COLS=['arr_delay']\n",
        ") AS\n",
        "{CANONICAL_BASE_SQL_REG}\n",
        "{SPLIT_CLAUSE_REG}\n",
        "SELECT\n",
        "  s.arr_delay,\n",
        "  s.dep_delay,\n",
        "  s.distance,\n",
        "  s.carrier,\n",
        "  s.origin,\n",
        "  s.dest,\n",
        "  EXTRACT(DAYOFWEEK FROM s.flight_date) AS day_of_week\n",
        "FROM split AS s\n",
        "WHERE s.data_split_col='TRAIN'\n",
        ";\n",
        "'''\n",
        "\n",
        "job = bq.query(sql_create_reg_model); _ = job.result()\n",
        "print(\"Regression model trained:\", MODEL_REG)\n"
      ],
      "id": "8e788d5b",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regression model trained: mgmt-467-55510.unit2_flights.clf_arr_delay_reg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "569c8638"
      },
      "source": [
        "## Evaluating the Regression Model\n",
        "\n",
        "Evaluating the trained `LINEAR_REG` model using `ML.EVALUATE` and interpret the Mean Absolute Error (MAE) in business terms for flight arrival delays.\n"
      ],
      "id": "569c8638"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08f90ff2"
      },
      "source": [
        "Constructing a SQL query to evaluate the trained LINEAR_REG model using ML.EVALUATE on the 'EVAL' split of the data, then executing the query and displaying the results.\n",
        "\n"
      ],
      "id": "08f90ff2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68cc9007",
        "outputId": "a3ef2801-3c2a-4c04-c3c5-23d20ad9b856"
      },
      "source": [
        "sql_evaluate_reg_model = f'''\n",
        "{CANONICAL_BASE_SQL_REG}\n",
        "{SPLIT_CLAUSE_REG}\n",
        "\n",
        "SELECT * FROM ML.EVALUATE(\n",
        "  MODEL `{MODEL_REG}`,\n",
        "  (SELECT\n",
        "     s.arr_delay,\n",
        "     s.dep_delay,\n",
        "     s.distance,\n",
        "     s.carrier,\n",
        "     s.origin,\n",
        "     s.dest,\n",
        "     EXTRACT(DAYOFWEEK FROM s.flight_date) AS day_of_week\n",
        "   FROM split AS s\n",
        "   WHERE s.data_split_col='EVAL')\n",
        ");\n",
        "'''\n",
        "\n",
        "evaluation_reg_df = bq.query(sql_evaluate_reg_model).to_dataframe()\n",
        "print(\"Regression model evaluation results:\")\n",
        "print(evaluation_reg_df)\n",
        "\n",
        "mae = evaluation_reg_df['mean_absolute_error'].iloc[0]\n",
        "print(f\"\\nMean Absolute Error (MAE): {mae:.2f} minutes\")\n",
        "print(f\"\\nBusiness Interpretation: On average, the model's predictions for arrival delays are off by {mae:.2f} minutes from the actual arrival delays. For example, if the model predicts a flight will be 10 minutes late, the actual delay could be 10 + {mae:.2f} minutes or 10 - {mae:.2f} minutes.\")"
      ],
      "id": "68cc9007",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regression model evaluation results:\n",
            "   mean_absolute_error  mean_squared_error  mean_squared_log_error  \\\n",
            "0             10.18274          204.661422                0.888686   \n",
            "\n",
            "   median_absolute_error  r2_score  explained_variance  \n",
            "0               7.605864  0.939952            0.939952  \n",
            "\n",
            "Mean Absolute Error (MAE): 10.18 minutes\n",
            "\n",
            "Business Interpretation: On average, the model's predictions for arrival delays are off by 10.18 minutes from the actual arrival delays. For example, if the model predicts a flight will be 10 minutes late, the actual delay could be 10 + 10.18 minutes or 10 - 10.18 minutes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd869b5d"
      },
      "source": [
        "## Explaining Regression Predictions\n",
        "\n",
        "Using `ML.EXPLAIN_PREDICT` to generate explanations for predictions on two hypothetical flights, identifying and interpreting the top contributing features for each prediction.\n"
      ],
      "id": "fd869b5d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8984830"
      },
      "source": [
        "\n",
        "Constructing an SQL query using `ML.EXPLAIN_PREDICT` on the trained `LINEAR_REG` model. This query will select a small subset of the evaluation data and output the predicted `arr_delay` along with feature contributions for analysis.\n",
        "\n"
      ],
      "id": "a8984830"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d66354e5",
        "outputId": "f84aa35c-1e54-4ebf-e990-ae3e523d50f0"
      },
      "source": [
        "sql_explain_predict = f'''\n",
        "{CANONICAL_BASE_SQL_REG}\n",
        "{SPLIT_CLAUSE_REG}\n",
        "\n",
        "SELECT * FROM ML.EXPLAIN_PREDICT(\n",
        "  MODEL `{MODEL_REG}`,\n",
        "  (SELECT\n",
        "     s.arr_delay, -- Included to show actual vs predicted\n",
        "     s.dep_delay,\n",
        "     s.distance,\n",
        "     s.carrier,\n",
        "     s.origin,\n",
        "     s.dest,\n",
        "     EXTRACT(DAYOFWEEK FROM s.flight_date) AS day_of_week\n",
        "   FROM split AS s\n",
        "   WHERE s.data_split_col='EVAL'\n",
        "   LIMIT 2)\n",
        ");\n",
        "'''\n",
        "\n",
        "explanations_df = bq.query(sql_explain_predict).to_dataframe()\n",
        "print(\"Regression model explanation predictions:\")\n",
        "print(explanations_df)"
      ],
      "id": "d66354e5",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regression model explanation predictions:\n",
            "   predicted_arr_delay                           top_feature_attributions  \\\n",
            "0           -19.442730  [{'feature': 'origin', 'attribution': -56117.5...   \n",
            "1            -2.632394  [{'feature': 'origin', 'attribution': -56117.5...   \n",
            "\n",
            "   baseline_prediction_value  prediction_value  approximation_error  \\\n",
            "0                5117.559449        -19.442730                  0.0   \n",
            "1                5117.559449         -2.632394                  0.0   \n",
            "\n",
            "   arr_delay  dep_delay  distance carrier origin dest  day_of_week  \n",
            "0      -23.0       -7.0     692.0      9E    ABE  ATL            6  \n",
            "1        2.0        9.0     692.0      9E    ABE  ATL            1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61c7ebc7"
      },
      "source": [
        "### Interpretation of `ML.EXPLAIN_PREDICT` Results\n",
        "\n",
        "The `ML.EXPLAIN_PREDICT` output provides insights into which features contribute most to the predicted `arr_delay` for each flight. Analysis of the two hypothetical flights:\n",
        "\n",
        "**Flight 1:**\n",
        "-   **Predicted `arr_delay`:** -19.44 minutes (indicating an early arrival)\n",
        "-   **Actual `arr_delay`:** -23.0 minutes\n",
        "-   **Top Feature Attributions:**\n",
        "    -   `origin` (e.g., ABE): This feature has a large negative attribution (-56117.5). Given the `baseline_prediction_value` is very large (5117.559449), it implies that a specific origin (ABE in this case) has a strong influence in reducing the predicted delay, contributing significantly towards an early arrival.\n",
        "    -   Other features are not explicitly shown with their full attributions in the truncated output, but `dep_delay` (-7.0) is a direct indicator of early departure, which would naturally contribute to an early arrival.\n",
        "\n",
        "**Flight 2:**\n",
        "-   **Predicted `arr_delay`:** -2.63 minutes (indicating a slight early arrival or on-time)\n",
        "-   **Actual `arr_delay`:** 2.0 minutes\n",
        "-   **Top Feature Attributions:**\n",
        "    -   `origin` (e.g., ABE): Similar to Flight 1, `origin` also has a very large negative attribution (-56117.5), again pushing the prediction towards an earlier arrival compared to the baseline. This suggests that flights originating from 'ABE' tend to be less delayed or even early.\n",
        "    -   `dep_delay` (9.0): This feature indicates the flight departed 9 minutes late. While the `origin` is pushing for an early arrival, the `dep_delay` of 9 minutes is a significant factor contributing to a *later* arrival, counteracting the early tendency from the origin. If not for the positive `dep_delay`, the flight might have been predicted to be even earlier.\n",
        "\n",
        "**Overall Interpretation:**\n",
        "\n",
        "The `top_feature_attributions` show that `origin` is a highly influential categorical feature for these specific predictions, with a strong negative attribution, indicating that the baseline model, which likely predicts a high default delay, is heavily adjusted downwards by the specific `origin` of these flights. The `dep_delay` feature also plays a direct role, as expected: a negative `dep_delay` (early departure) contributes to an early arrival, and a positive `dep_delay` (late departure) contributes to a later arrival, modifying the `origin`'s influence."
      ],
      "id": "61c7ebc7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f0555a4"
      },
      "source": [
        "## Cost and Scale: Development Iterations with LIMIT\n",
        "\n",
        "\n",
        "Demonstrating the use of the `LIMIT` clause in BigQuery SQL queries to create smaller datasets for faster development iterations and cost control during model experimentation.\n"
      ],
      "id": "9f0555a4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f01a80b"
      },
      "source": [
        "\n",
        "Constructing an SQL query that leverages the existing canonical flight data and splitting logic, adding a `LIMIT` clause to demonstrate how to create a smaller dataset for quicker development iterations and cost control. This will involve re-using previously defined SQL components and appending a `LIMIT` to the final `SELECT` statement.\n",
        "\n"
      ],
      "id": "4f01a80b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de1937c4",
        "outputId": "ac744b58-46b7-4fda-b61f-1390d293df50"
      },
      "source": [
        "PROJECT_ID = \"mgmt-467-55510\"\n",
        "TABLE_PATH = \"mgmt-467-55510.unit2_flights.flights_data_2023_1_from_gcs\" # Current TABLE_PATH from kernel state\n",
        "\n",
        "CANONICAL_BASE_SQL = f'''\n",
        "WITH canonical_flights AS (\n",
        "  SELECT\n",
        "    CAST(FlightDate AS DATE) AS flight_date,\n",
        "    CAST(DepDelay AS FLOAT64) AS dep_delay,\n",
        "    CAST(distance  AS FLOAT64) AS distance,\n",
        "    CAST(Reporting_Airline   AS STRING)  AS carrier,\n",
        "    CAST(Origin    AS STRING)  AS origin,\n",
        "    CAST(Dest AS STRING) AS dest,\n",
        "    CAST((CASE WHEN SAFE_CAST(Diverted AS INT64)=1 OR LOWER(CAST(Diverted AS STRING))='true' THEN TRUE ELSE FALSE END) AS BOOL) AS diverted\n",
        "  FROM `{TABLE_PATH}`\n",
        "  WHERE DepDelay IS NOT NULL\n",
        ")\n",
        "'''\n",
        "\n",
        "SPLIT_CLAUSE = r'''\n",
        ", split AS (\n",
        "  SELECT cf.*,\n",
        "         CASE WHEN RAND() < 0.8 THEN 'TRAIN' ELSE 'EVAL' END AS split\n",
        "  FROM canonical_flights cf\n",
        ")\n",
        "'''\n",
        "\n",
        "# Construct the training data query with CTEs and a LIMIT clause\n",
        "sql_training_query_limited = f'''\n",
        "{CANONICAL_BASE_SQL}\n",
        "{SPLIT_CLAUSE}\n",
        "SELECT\n",
        "  s.diverted,\n",
        "  s.dep_delay, s.distance, s.carrier, s.origin, s.dest,\n",
        "  EXTRACT(DAYOFWEEK FROM s.flight_date) AS day_of_week\n",
        "FROM split AS s\n",
        "WHERE s.split='TRAIN'\n",
        "LIMIT 1000;\n",
        "'''\n",
        "\n",
        "print(\"SQL query demonstrating LIMIT for development iterations:\")\n",
        "print(sql_training_query_limited)"
      ],
      "id": "de1937c4",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SQL query demonstrating LIMIT for development iterations:\n",
            "\n",
            "\n",
            "WITH canonical_flights AS (\n",
            "  SELECT\n",
            "    CAST(FlightDate AS DATE) AS flight_date,\n",
            "    CAST(DepDelay AS FLOAT64) AS dep_delay,\n",
            "    CAST(distance  AS FLOAT64) AS distance,\n",
            "    CAST(Reporting_Airline   AS STRING)  AS carrier,\n",
            "    CAST(Origin    AS STRING)  AS origin,\n",
            "    CAST(Dest AS STRING) AS dest,\n",
            "    CAST((CASE WHEN SAFE_CAST(Diverted AS INT64)=1 OR LOWER(CAST(Diverted AS STRING))='true' THEN TRUE ELSE FALSE END) AS BOOL) AS diverted\n",
            "  FROM `mgmt-467-55510.unit2_flights.flights_data_2023_1_from_gcs`\n",
            "  WHERE DepDelay IS NOT NULL\n",
            ")\n",
            "\n",
            "\n",
            ", split AS (\n",
            "  SELECT cf.*,\n",
            "         CASE WHEN RAND() < 0.8 THEN 'TRAIN' ELSE 'EVAL' END AS split\n",
            "  FROM canonical_flights cf\n",
            ")\n",
            "\n",
            "SELECT\n",
            "  s.diverted,\n",
            "  s.dep_delay, s.distance, s.carrier, s.origin, s.dest,\n",
            "  EXTRACT(DAYOFWEEK FROM s.flight_date) AS day_of_week\n",
            "FROM split AS s\n",
            "WHERE s.split='TRAIN'\n",
            "LIMIT 1000;\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Performance Review and Analysis of True Positive Failures\n",
        "\n",
        "#### 1. Evaluation Metrics\n",
        "\n",
        "**Baseline Model (from `evaluation_df` in cell `df945eb0`):**\n",
        "- **AUC:** 0.800851\n",
        "- **Precision:** 0.0\n",
        "- **Recall:** 0.0\n",
        "- **Accuracy:** 0.997446\n",
        "- **Log Loss:** 0.0162\n",
        "\n",
        "**Engineered Model (from `evaluation_xform_df` in cell `df201838`):**\n",
        "- **AUC:** 0.892322\n",
        "- **Precision:** 0.25\n",
        "- **Recall:** 0.017668\n",
        "- **Accuracy:** 0.997241\n",
        "- **Log Loss:** 0.015694\n",
        "\n",
        "#### 2. Confusion Matrices (Baseline Model)\n",
        "\n",
        "**Default Threshold (0.5) (from cell `b9b9617b`):**\n",
        "- **TP (True Positives):** 0\n",
        "- **FP (False Positives):** 0\n",
        "- **FN (False Negatives):** 256\n",
        "- **TN (True Negatives):** 105184\n",
        "\n",
        "**Custom Threshold (0.75) (from cell `aae9d273`):**\n",
        "- **TP (True Positives):** 0\n",
        "- **FP (False Positives):** 0\n",
        "- **FN (False Negatives):** 270\n",
        "- **TN (True Negatives):** 105264\n",
        "\n",
        "#### 3. Analysis of True Positive Predictions\n",
        "\n",
        "The most notable observation from both the evaluation metrics and the confusion matrices is the near-total absence of True Positive (TP) predictions. The baseline model, at both default (0.5) and custom (0.75) thresholds, predicts **zero** true positives. The engineered model shows a very low recall (0.017668), indicating it predicts a very small number of true positives, likely only a handful out of over 250 actual positive cases. Its precision is 0.25, meaning 25% of its positive predictions are correct, but it makes very few such predictions.\n",
        "\n",
        "This strategy yields high TN and low FP, but also high FN and low TP, leading to very low precision and recall for the minority class.\n",
        "\n",
        "To improve true positive predictions, it would likely be necessary to:\n",
        "\n",
        "1.  **Adjust the prediction threshold**: Explore significantly lower thresholds (e.g., 0.01, 0.05, 0.1) to see if true positives emerge, while monitoring the trade-off with false positives.\n",
        "2.  **Address class imbalance**: Implement techniques such as oversampling the minority class, undersampling the majority class, or using algorithms specifically designed for imbalanced datasets."
      ],
      "metadata": {
        "id": "dJ21reyBD2VY"
      },
      "id": "dJ21reyBD2VY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Analysis Key Findings\n",
        "\n",
        "*   A BigQuery ML `LINEAR_REG` model was successfully trained to predict flight arrival delays (`arr_delay`) using features such as `dep_delay`, `distance`, `carrier`, `origin`, `dest`, and `day_of_week`.\n",
        "\n",
        "*   Key Findings\n",
        "\n",
        "    Regression Performance: A BigQuery ML LINEAR_REG model trained on flight features predicted arrival delay (arr_delay) with a Mean Absolute Error (MAE) of 10.18 minutes. This means predictions are off by about 10 minutes on average.\n",
        "\n",
        "    Feature Importance: ML.EXPLAIN_PREDICT showed that origin (e.g., 'ABE') was a highly influential feature, significantly contributing to predictions of earlier arrivals. dep_delay also played a direct, expected role.\n",
        "\n",
        "    Cost Management: The LIMIT clause is crucial for cost control in BQML. It allows for rapid, cost-effective development cycles by processing small, sampled datasets for prototyping.\n",
        "\n",
        "    Deployment Strategy: A dual-approach is recommended: sampled data for agile development and the full dataset for the final production model to maximize performance and robustness, despite the higher cost.\n",
        "\n",
        "Next Steps\n",
        "\n",
        "* Improve MAE: Enhance the model by exploring advanced BQML models (BOOSTED_TREE_REGRESSOR) or implementing deeper feature engineering (e.g., interaction terms) to reduce the 10.18-minute error.\n",
        "\n",
        "* Refine Sampling: Use structured sampling (e.g., stratified sampling) over a simple LIMIT during early prototyping to ensure subsets are representative of the full dataset.\n"
      ],
      "metadata": {
        "id": "l1z5gEIeFTYS"
      },
      "id": "l1z5gEIeFTYS"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a45ec304"
      },
      "source": [
        "## Cost and Scale: Final Run Plan (Sample vs. Full Table)\n",
        "\n",
        "The strategy for a 'final' model run, outline of the trade-offs between using a sampled dataset (for efficiency) and the full dataset (for completeness) in terms of model performance, cost, and training time.\n"
      ],
      "id": "a45ec304"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a190c1cb"
      },
      "source": [
        "The recommended strategy balances cost-effective development with production-ready performance by leveraging sampled and full datasets at different stages:\n",
        "\n",
        "Development & Experimentation (Use Sampled Data)\n",
        "\n",
        "* Goal: Rapid iteration and cost control.\n",
        "\n",
        "* Method: Use sampled datasets (e.g., LIMIT clause in BigQuery) for initial model training, feature engineering, and tuning.\n",
        "\n",
        "* Benefits: Faster iterations and significantly reduced costs by processing less data.\n",
        "\n",
        "Final Training & Deployment (Use Full Data)\n",
        "\n",
        "* Goal: Maximize model performance, robustness, and generalization for production.\n",
        "\n",
        "* Method: Train the final model on the full dataset once the architecture is finalized.\n",
        "\n",
        "* Trade-offs: Accepts increased cost and longer training time as a necessary investment for the highest quality, most reliable production model."
      ],
      "id": "a190c1cb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Limitation: Severe Class Imbalance\n",
        "\n",
        "The primary challenge for predicting diverted flights was severe class imbalance.\n",
        "\n",
        "* Result: Models achieved high overall accuracy (around 99.7%) but failed to correctly predict the rare diverted class.\n",
        "\n",
        "* Metrics: The baseline model had zero true positives. The engineered model showed low recall (0.017668) and low precision (0.25).\n",
        "\n",
        "* Resolution: This necessitates either significantly lowering the prediction threshold or implementing direct class imbalance techniques.\n",
        "\n",
        "Cost & Scaling Strategy (BigQuery ML)\n",
        "\n",
        "* Development Iterations: Use the LIMIT clause on datasets (e.g., LIMIT 1000) for cost control and faster, agile prototyping to accelerate testing and debugging.\n",
        "\n",
        "* Final Run: Employ a dual-strategy: use small, sampled data for cost-effective experimentation, but train the final production model on the full dataset. This maximizes model performance, robustness, and generalization, accepting the necessary higher costs and longer training times."
      ],
      "metadata": {
        "id": "Tzs3dUYCDbtV"
      },
      "id": "Tzs3dUYCDbtV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Write-up (Concise)\n",
        "\n",
        "-   **Threshold chosen & ops rationale:** Both baseline and engineered models produced zero true positives for 'diverted' flights at 0.5 and 0.75 thresholds. This indicates severe class imbalance and consistently low predicted probabilities for actual diversions, rendering these thresholds ineffective. A significantly lower threshold or class imbalance techniques are necessary to identify any diverted flights.\n",
        "\n",
        "-   **Baseline vs engineered — observed changes in AUC/precision/recall:** The engineered model improved AUC to 0.892 (from baseline's 0.801). However, its recall (0.0177) and precision (0.25) for 'diverted' flights remained extremely low, indicating minimal practical improvement in identifying actual diversions.\n",
        "\n",
        "-   **Risk framing:** The cost of False Negatives (FN - missing a diversion) is far greater than False Positives (FP - unnecessary planning). With 256-270 missed diversions (FNs), the current models are operationally unacceptable. Minimizing FN-rate, likely by prioritizing recall through threshold adjustment or imbalance techniques, is critical for safety and efficiency."
      ],
      "metadata": {
        "id": "11fDxiTaQqbf"
      },
      "id": "11fDxiTaQqbf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b79ee21"
      },
      "source": [
        "# Generating the SQL file\n"
      ],
      "id": "0b79ee21"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# --- Re-define/Extract Variables ---\n",
        "PROJECT_ID = \"mgmt-467-55510\"\n",
        "DATASET_ID = \"unit2_flights\"\n",
        "TABLE_PATH = \"mgmt-467-55510.unit2_flights.flights_data_2023_1_from_gcs\"\n",
        "REGION = \"us\"\n",
        "\n",
        "# Constants\n",
        "CUSTOM_THRESHOLD = 0.75\n",
        "\n",
        "# Model names\n",
        "MODEL_BASE = f\"{PROJECT_ID}.{DATASET_ID}.clf_diverted_base\"\n",
        "MODEL_XFORM = f\"{PROJECT_ID}.{DATASET_ID}.clf_diverted_xform\"\n",
        "MODEL_REG = f\"{PROJECT_ID}.{DATASET_ID}.reg_arr_delay_reg\" # Using a slightly clearer name for the final script\n",
        "\n",
        "# --- 1. Define the SQL Content Blocks ---\n",
        "\n",
        "# Configuration and Variable Declaration Block\n",
        "config_and_vars = f'''\n",
        "-- 0 -- CONFIG & VARIABLES\n",
        "======================================================\n",
        "DECLARE PROJECT_ID STRING DEFAULT '{PROJECT_ID}';\n",
        "DECLARE DATASET_ID STRING DEFAULT '{DATASET_ID}';\n",
        "DECLARE TABLE_PATH STRING DEFAULT '{TABLE_PATH}';\n",
        "\n",
        "-- Classification hyperparameters/costs (can be tuned)\n",
        "DECLARE THRESH FLOAT64 DEFAULT {CUSTOM_THRESHOLD};\n",
        "DECLARE C_FP INT64 DEFAULT 1000;\n",
        "DECLARE C_FN INT64 DEFAULT 6000;\n",
        "\n",
        "-- Model names (built dynamically)\n",
        "DECLARE MODEL_BASE STRING;\n",
        "DECLARE MODEL_ENG STRING;\n",
        "DECLARE MODEL_REG STRING;\n",
        "\n",
        "-- Assign model names after declarations\n",
        "SET MODEL_BASE = FORMAT(\"%s.%s.clf_diverted_base\", PROJECT_ID, DATASET_ID);\n",
        "SET MODEL_ENG = FORMAT(\"%s.%s.clf_diverted_engineered\", PROJECT_ID, DATASET_ID);\n",
        "SET MODEL_REG = FORMAT(\"%s.%s.reg_arr_delay\", PROJECT_ID, DATASET_ID);\n",
        "\n",
        "-- Create schema if needed\n",
        "EXECUTE IMMEDIATE FORMAT(\"\"\"\n",
        "CREATE SCHEMA IF NOT EXISTS %s.%s;\n",
        "\"\"\", PROJECT_ID, DATASET_ID);\n",
        "'''\n",
        "\n",
        "# Canonical CTE definition (used for the regression model, includes ArrDelay)\n",
        "canonical_cte_reg = '''\n",
        "  SELECT\n",
        "    CAST(FlightDate AS DATE) AS flight_date,\n",
        "    CAST(DepDelay AS FLOAT64) AS dep_delay,\n",
        "    CAST(ArrDelay AS FLOAT64) AS arr_delay,\n",
        "    CAST(distance  AS FLOAT64) AS distance,\n",
        "    CAST(Reporting_Airline AS STRING) AS carrier,\n",
        "    CAST(Origin AS STRING) AS origin,\n",
        "    CAST(Dest AS STRING) AS dest,\n",
        "    CAST((CASE WHEN SAFE_CAST(Diverted AS INT64)=1 OR LOWER(CAST(Diverted AS STRING))='true' THEN TRUE ELSE FALSE END) AS BOOL) AS diverted\n",
        "  FROM `${TABLE_PATH}`\n",
        "  WHERE DepDelay IS NOT NULL AND ArrDelay IS NOT NULL -- Required filter for regression\n",
        "'''\n",
        "\n",
        "# Split CTE definition for Regression (uses `data_split_col`)\n",
        "split_cte_reg = '''\n",
        ", split AS (\n",
        "  SELECT cf.*,\n",
        "         CASE WHEN RAND() < 0.8 THEN 'TRAIN' ELSE 'EVAL' END AS data_split_col\n",
        "  FROM canonical_flights cf\n",
        ")\n",
        "'''\n",
        "\n",
        "\n",
        "# --- 2. Model Training and Evaluation Blocks ---\n",
        "\n",
        "# 2.1 Regression Model Training (LINEAR_REG)\n",
        "regression_model_train = f'''\n",
        "-- 3) REGRESSION MODEL — LINEAR_REG (Predicts arr_delay)\n",
        "======================================================\n",
        "\n",
        "CREATE OR REPLACE MODEL ${{MODEL_REG}}\n",
        "OPTIONS (\n",
        "  MODEL_TYPE='LINEAR_REG',\n",
        "  INPUT_LABEL_COLS=['arr_delay']\n",
        ") AS\n",
        "WITH canonical_flights AS (\n",
        "{canonical_cte_reg}\n",
        ")\n",
        "{split_cte_reg}\n",
        "SELECT\n",
        "  s.arr_delay,\n",
        "  s.dep_delay,\n",
        "  s.distance,\n",
        "  s.carrier,\n",
        "  s.origin,\n",
        "  s.dest,\n",
        "  EXTRACT(DAYOFWEEK FROM s.flight_date) AS day_of_week\n",
        "FROM split AS s\n",
        "WHERE s.data_split_col='TRAIN';\n",
        "'''\n",
        "\n",
        "# 2.2 Regression Model Evaluation\n",
        "regression_model_evaluate = f'''\n",
        "-- 4) REGRESSION MODEL EVALUATION (MAE, R2)\n",
        "======================================================\n",
        "\n",
        "SELECT * FROM ML.EVALUATE(\n",
        "  MODEL ${{MODEL_REG}},\n",
        "  (\n",
        "    WITH canonical_flights AS (\n",
        "{canonical_cte_reg}\n",
        "    )\n",
        "    {split_cte_reg}\n",
        "    SELECT\n",
        "      s.arr_delay,\n",
        "      s.dep_delay,\n",
        "      s.distance,\n",
        "      s.carrier,\n",
        "      s.origin,\n",
        "      s.dest,\n",
        "      EXTRACT(DAYOFWEEK FROM s.flight_date) AS day_of_week\n",
        "    FROM split AS s\n",
        "    WHERE s.data_split_col='EVAL'\n",
        "  )\n",
        ");\n",
        "'''\n",
        "\n",
        "# 2.3 Regression Model Explain Predict (Limit 2 rows)\n",
        "regression_model_explain = f'''\n",
        "-- 5) REGRESSION MODEL EXPLAIN PREDICT (Feature Attribution)\n",
        "======================================================\n",
        "\n",
        "SELECT * FROM ML.EXPLAIN_PREDICT(\n",
        "  MODEL ${{MODEL_REG}},\n",
        "  (\n",
        "    WITH canonical_flights AS (\n",
        "{canonical_cte_reg}\n",
        "    )\n",
        "    {split_cte_reg}\n",
        "    SELECT\n",
        "      s.arr_delay,\n",
        "      s.dep_delay,\n",
        "      s.distance,\n",
        "      s.carrier,\n",
        "      s.origin,\n",
        "      s.dest,\n",
        "      EXTRACT(DAYOFWEEK FROM s.flight_date) AS day_of_week\n",
        "    FROM split AS s\n",
        "    WHERE s.data_split_col='EVAL'\n",
        "    LIMIT 2\n",
        "  )\n",
        ");\n",
        "'''\n",
        "\n",
        "# --- 3. Combine Blocks and Write to File ---\n",
        "\n",
        "baseline_model_placeholder = f'''\n",
        "-- 1) BASELINE CLASSIFICATION MODEL — LOGISTIC_REG (TRAINING BLOCK)\n",
        "-- ... (Full SQL to create model $MODEL_BASE) ...\n",
        "'''\n",
        "\n",
        "engineered_model_placeholder = f'''\n",
        "-- 2) ENGINEERED CLASSIFICATION MODEL — LOGISTIC_REG with TRANSFORM (TRAINING BLOCK)\n",
        "-- ... (Full SQL to create model $MODEL_ENG) ...\n",
        "'''\n",
        "\n",
        "full_sql_script = \"\\n\\n\".join([\n",
        "    config_and_vars,\n",
        "    baseline_model_placeholder,\n",
        "    engineered_model_placeholder,\n",
        "    regression_model_train,\n",
        "    regression_model_evaluate,\n",
        "    regression_model_explain\n",
        "])\n",
        "\n",
        "sql_file_name = \"full_bqml_script_with_reg_eval.sql\"\n",
        "with open(sql_file_name, \"w\") as f:\n",
        "    f.write(full_sql_script)\n",
        "\n",
        "print(f\"✅ Successfully created '{sql_file_name}'.\")\n",
        "print(\"This file contains the configuration, both classification model training blocks (placeholders here), and the full regression model training, evaluation, and explanation queries.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WN7u2icnM3K_",
        "outputId": "6c69c0a6-1492-46bf-ea03-68e859b1b53f"
      },
      "id": "WN7u2icnM3K_",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Successfully created 'full_bqml_script_with_reg_eval.sql'.\n",
            "This file contains the configuration, both classification model training blocks (placeholders here), and the full regression model training, evaluation, and explanation queries.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}